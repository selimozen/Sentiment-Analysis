{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing  import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"stock_data.csv\", encoding = \"ISO-8859-1\", engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tr - Twitterdan toplanmış ve 2'ye bölünmüş hisse senedi haberleri.\n",
    "\n",
    "ENG - Gathered Stock news from Multiple twitter Handles regarding Economic news dividing into two parts : Negative(-1) and positive(1) .\n",
    "\n",
    "Negative count: 2,106\n",
    "\n",
    "Positive count: 3,685\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>Industry body CII said #discoms are likely to ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>#Gold prices slip below Rs 46,000 as #investor...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>Workers at Bajaj Auto have agreed to a 10% wag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>#Sharemarket LIVE: Sensex off dayâs high, up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>#Sensex, #Nifty climb off day's highs, still u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5791 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment\n",
       "0     Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1     user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2     user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                     MNTA Over 12.00            1\n",
       "4                                      OI  Over 21.37            1\n",
       "...                                                 ...        ...\n",
       "5786  Industry body CII said #discoms are likely to ...         -1\n",
       "5787  #Gold prices slip below Rs 46,000 as #investor...         -1\n",
       "5788  Workers at Bajaj Auto have agreed to a 10% wag...          1\n",
       "5789  #Sharemarket LIVE: Sensex off dayâs high, up...          1\n",
       "5790  #Sensex, #Nifty climb off day's highs, still u...          1\n",
       "\n",
       "[5791 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tr - Veri setine ilk bakış\n",
    "\n",
    "Eng - First look at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5791 entries, 0 to 5790\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Text       5791 non-null   object\n",
      " 1   Sentiment  5791 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    3685\n",
       "-1    2106\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tr - Veri ön işleme\n",
    "\n",
    "Eng - Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Sentiment\"] = data[\"Sentiment\"].replace(-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"Text\"] = data[\"Text\"].apply(lambda x: TextBlob(x).words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(data[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tr- Basit bir özellik çıkarımı.\n",
    "Text verilerimizi tokenleştirip kelimeleri bir integer olarak atıyoruz. Sonra modele vereceğimiz cümlelerimizin boyutunu belirliyoruz. Bu önemlidir, çünkü çok fazla boyutlu kelimeler modelimizi yorabilir veya az geçen, bir öneme sahip olmaya kelimelerimizide vermiş olabiliriz.\n",
    "\n",
    "Eng- Simple feature extraction.\n",
    "We specify our text data and throw out the words as whole numbers. Then we determine the size of our sentences that we will give to the model.This is important because we can tire our model of words with too many dimensions, or we may have given meaningless words to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tokens = tokenizer.texts_to_sequences(data[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[742, 1317, 269, 395, 1009, 1010, 4629, 468, 205]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tokens[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HA Hitting 35.65 means resume targeting 42 level ..  '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Text\"][15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tr - Buraya kadar tokenleştirme işlemini yaptık. Burdan sonra ise özellik çıkarımı yaparak kelimelerimizi hem vektörleştiriyoruz, hemde dediğimiz gibi modelimize vereceğimiz cümlelerin boyutunu beliyorluyoruz.\n",
    "\n",
    "Eng- After that, we do feature extraction. We both vectorize and, as I said, determine the sentences we will give to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in data_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(num_tokens < max_tokens) / len(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tr - Veri setimizde 26'dan fazla kelimeden oluşan cümlelerimizin veri setimize oranı sadece %7.\n",
    "\n",
    "Eng - The ratio of our sentences consisting of more than 26 words in the data set to our data set is only %7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pad = pad_sequences(data_tokens, maxlen = max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5791, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tr - Model Eğitimi\n",
    "\n",
    "Eng - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences, test_sequences, y_train, y_test = train_test_split(data_pad, data[\"Sentiment\"], train_size=0.8, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tr - Modelimizi oluşutuyoruz.\n",
    "\n",
    "Eng - We create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tr - Kelime matrisimizi oluşturuyoruz. Ben deneyerek en başarılı paramtreleri bu şekilde buldum.\n",
    "\n",
    "Eng - We create our word matrix. This is how I found the most successful parameters by trying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(input_dim = 50000,\n",
    "                    output_dim = 300,\n",
    "                   input_length = max_tokens,\n",
    "                   name = \"embeding_layer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(units = 64, return_sequences = True))\n",
    "model.add(GRU(units = 32, return_sequences = True))\n",
    "model.add(GRU(units = 16, return_sequences = True))\n",
    "model.add(GRU(units = 8, return_sequences = True))\n",
    "model.add(GRU(units = 4, return_sequences = False))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr = 3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = optimizer,\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embeding_layer (Embedding)   (None, 28, 300)           7500000   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 28, 64)            70272     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 28, 32)            9408      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 28, 16)            2400      \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 28, 8)             624       \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 4)                 168       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 7,582,877\n",
      "Trainable params: 7,582,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "145/145 [==============================] - 33s 228ms/step - loss: 0.6779 - accuracy: 0.6235\n",
      "Epoch 2/20\n",
      "145/145 [==============================] - 34s 231ms/step - loss: 0.6569 - accuracy: 0.6332\n",
      "Epoch 3/20\n",
      "145/145 [==============================] - 32s 222ms/step - loss: 0.6459 - accuracy: 0.6332\n",
      "Epoch 4/20\n",
      "145/145 [==============================] - 36s 251ms/step - loss: 0.6322 - accuracy: 0.6364\n",
      "Epoch 5/20\n",
      "145/145 [==============================] - 32s 223ms/step - loss: 0.5996 - accuracy: 0.6734\n",
      "Epoch 6/20\n",
      "145/145 [==============================] - 31s 213ms/step - loss: 0.5297 - accuracy: 0.7649\n",
      "Epoch 7/20\n",
      "145/145 [==============================] - 31s 216ms/step - loss: 0.4483 - accuracy: 0.8413\n",
      "Epoch 8/20\n",
      "145/145 [==============================] - 37s 252ms/step - loss: 0.3856 - accuracy: 0.8772\n",
      "Epoch 9/20\n",
      "145/145 [==============================] - 32s 221ms/step - loss: 0.3429 - accuracy: 0.9011\n",
      "Epoch 10/20\n",
      "145/145 [==============================] - 32s 220ms/step - loss: 0.3081 - accuracy: 0.9193\n",
      "Epoch 11/20\n",
      "145/145 [==============================] - 32s 221ms/step - loss: 0.2795 - accuracy: 0.9335\n",
      "Epoch 12/20\n",
      "145/145 [==============================] - 32s 220ms/step - loss: 0.2575 - accuracy: 0.9454\n",
      "Epoch 13/20\n",
      "145/145 [==============================] - 32s 221ms/step - loss: 0.2408 - accuracy: 0.9516\n",
      "Epoch 14/20\n",
      "145/145 [==============================] - 34s 237ms/step - loss: 0.2282 - accuracy: 0.9551\n",
      "Epoch 15/20\n",
      "145/145 [==============================] - 33s 230ms/step - loss: 0.2140 - accuracy: 0.9611\n",
      "Epoch 16/20\n",
      "145/145 [==============================] - 32s 223ms/step - loss: 0.2024 - accuracy: 0.9655\n",
      "Epoch 17/20\n",
      "145/145 [==============================] - 32s 222ms/step - loss: 0.1925 - accuracy: 0.9696\n",
      "Epoch 18/20\n",
      "145/145 [==============================] - 32s 219ms/step - loss: 0.1838 - accuracy: 0.9711\n",
      "Epoch 19/20\n",
      "145/145 [==============================] - 32s 222ms/step - loss: 0.1747 - accuracy: 0.9752\n",
      "Epoch 20/20\n",
      "145/145 [==============================] - 32s 221ms/step - loss: 0.1685 - accuracy: 0.9769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21345823940>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sequences, y_train, epochs = 20, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test Loss: 0.54987\n",
      "Test Accuracy: 76.10%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_sequences, y_test, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
